{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dVdxOzjxUH4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpDCcpA2TGLh"
      },
      "outputs": [],
      "source": [
        "# Weighted Weak Linear Classifier\n",
        "class WeightedWeakLinearClassifier:\n",
        "    def __init__(self):\n",
        "        self.threshold = None\n",
        "        self.orientation_vector = None\n",
        "        self.polarity = None\n",
        "\n",
        "    def fit(self, X, y, weights):\n",
        "        # Calculate weighted means\n",
        "        pos_weights = weights[y == 1]\n",
        "        neg_weights = weights[y == -1]\n",
        "        pos_mean = np.average(X[y == 1], axis=0, weights=pos_weights)\n",
        "        neg_mean = np.average(X[y == -1], axis=0, weights=neg_weights)\n",
        "\n",
        "        # Orientation vector\n",
        "        self.orientation_vector = pos_mean - neg_mean\n",
        "        norm = np.linalg.norm(self.orientation_vector)\n",
        "        self.orientation_vector /= norm\n",
        "\n",
        "        # Project points\n",
        "        projections = np.dot(X, self.orientation_vector)\n",
        "\n",
        "        # Sort projections\n",
        "        sorted_indices = np.argsort(projections)\n",
        "        sorted_projections = projections[sorted_indices]\n",
        "        sorted_y = y[sorted_indices]\n",
        "        sorted_weights = weights[sorted_indices]\n",
        "\n",
        "        # Find the best split\n",
        "        min_error = float('inf')\n",
        "        for i in range(len(sorted_projections) - 1):\n",
        "            threshold = (sorted_projections[i] + sorted_projections[i + 1]) / 2\n",
        "            polarity = 1\n",
        "            error = np.sum(sorted_weights[(sorted_y != polarity * np.sign(sorted_projections - threshold))])\n",
        "            if error < min_error:\n",
        "                min_error = error\n",
        "                self.threshold = threshold\n",
        "                self.polarity = polarity\n",
        "\n",
        "    def predict(self, X):\n",
        "        projections = np.dot(X, self.orientation_vector)\n",
        "        return self.polarity * np.sign(projections - self.threshold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost\n",
        "class AdaBoost:\n",
        "    def __init__(self, n_learners):\n",
        "        self.n_learners = n_learners\n",
        "        self.learners = []\n",
        "        self.alphas = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(y)\n",
        "        weights = np.ones(n_samples) / n_samples\n",
        "        for _ in range(self.n_learners):\n",
        "            # Train weak learner\n",
        "            learner = WeightedWeakLinearClassifier()\n",
        "            learner.fit(X, y, weights)\n",
        "            predictions = learner.predict(X)\n",
        "\n",
        "            # Calculate weighted error\n",
        "            error = np.sum(weights[predictions != y])\n",
        "            if error > 0.5:\n",
        "                break\n",
        "\n",
        "            # Calculate alpha and update weights\n",
        "            alpha = 0.5 * np.log((1 - error) / error)\n",
        "            weights *= np.exp(-alpha * y * predictions)\n",
        "            weights /= np.sum(weights)\n",
        "\n",
        "            # Store learner and alpha\n",
        "            self.learners.append(learner)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "    def predict(self, X):\n",
        "        final_prediction = np.zeros(X.shape[0])\n",
        "        for learner, alpha in zip(self.learners, self.alphas):\n",
        "            final_prediction += alpha * learner.predict(X)\n",
        "        return np.sign(final_prediction)\n",
        "\n"
      ],
      "metadata": {
        "id": "CxiwD-fdTQj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization and Evaluation\n",
        "def evaluate_adaboost(X_train, y_train, X_test, y_test, n_learners):\n",
        "    adaboost = AdaBoost(n_learners)\n",
        "    adaboost.fit(X_train, y_train)\n",
        "\n",
        "    train_predictions = adaboost.predict(X_train)\n",
        "    test_predictions = adaboost.predict(X_test)\n",
        "\n",
        "    train_accuracy = np.mean(train_predictions == y_train)\n",
        "    test_accuracy = np.mean(test_predictions == y_test)\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpFO6iqiTU9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "train_data = np.loadtxt('/content/adaboost-train-24.txt')\n",
        "test_data = np.loadtxt('/content/adaboost-test-24.txt')\n",
        "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
        "X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
        "\n"
      ],
      "metadata": {
        "id": "3HTd0LYFTXk8",
        "outputId": "9cdb0078-dffb-449f-cd82-e33862a88f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "/content/adaboost-train-24.txt not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a9cad91b5a8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/adaboost-train-24.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/adaboost-test-24.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/adaboost-train-24.txt not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "# n_learners = 50\n",
        "# train_accuracies, test_accuracies = [], []\n",
        "# for n in range(1, n_learners + 1):\n",
        "#     train_acc, test_acc = evaluate_adaboost(X_train, y_train, X_test, y_test, n)\n",
        "#     train_accuracies.append(train_acc)\n",
        "#     test_accuracies.append(test_acc)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model and collect accuracy trends\n",
        "n_learners = 50  # Maximum number of learners to analyze\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for n in range(1, n_learners + 1):\n",
        "    adaboost = AdaBoost(n_learners=n)\n",
        "    adaboost.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions for training and testing sets\n",
        "    train_predictions = adaboost.predict(X_train)\n",
        "    test_predictions = adaboost.predict(X_test)\n",
        "\n",
        "    # Calculate accuracies\n",
        "    train_accuracy = np.mean(train_predictions == y_train) * 100\n",
        "    test_accuracy = np.mean(test_predictions == y_test) * 100\n",
        "\n",
        "    # Append results\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "# Print the trends in tabular format\n",
        "print(f\"{'Number of Learners':<20}{'Training Accuracy (%)':<25}{'Testing Accuracy (%)':<25}\")\n",
        "print(\"-\" * 70)\n",
        "for i in range(n_learners):\n",
        "    print(f\"{i+1:<20}{train_accuracies[i]:<25.2f}{test_accuracies[i]:<25.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zTajqXn_Taex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "plt.plot(range(1, n_learners + 1), train_accuracies, label=\"Train Accuracy\")\n",
        "plt.plot(range(1, n_learners + 1), test_accuracies, label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Number of Weak Learners\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "56OnhzyaTdDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}